<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Re:Log</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Re:Log</description>
    <generator>Hugo -- 0.152.1</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 17 Jan 2026 15:06:44 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>UrbanLF: A Comprehensive Light Field Dataset for Semantic Segmentation of Urban Scenes</title>
      <link>http://localhost:1313/posts/2026-01-17-urbanlf-a-comprehensive-light-field-dataset-for-se/</link>
      <pubDate>Sat, 17 Jan 2026 15:06:44 +0000</pubDate>
      <guid>http://localhost:1313/posts/2026-01-17-urbanlf-a-comprehensive-light-field-dataset-for-se/</guid>
      <description>Paper-reading notes: UrbanLF</description>
    </item>
    <item>
      <title>Large Concept Models: Language Modeling in a Sentence Representation Space</title>
      <link>http://localhost:1313/posts/2026-01-15-large-concept-models-language-modeling-in-a-senten/</link>
      <pubDate>Thu, 15 Jan 2026 14:54:13 +0000</pubDate>
      <guid>http://localhost:1313/posts/2026-01-15-large-concept-models-language-modeling-in-a-senten/</guid>
      <description>Paper-reading notes: Large Concept Models: Language Modeling in a Sentence Representation Space</description>
    </item>
    <item>
      <title>From Tokens To Thoughts: How LLMs And Humans Trade Compression For Meaning</title>
      <link>http://localhost:1313/posts/2026-01-12-from-tokens-to-thoughts-how-llms-and-humans-trade/</link>
      <pubDate>Mon, 12 Jan 2026 14:49:45 +0000</pubDate>
      <guid>http://localhost:1313/posts/2026-01-12-from-tokens-to-thoughts-how-llms-and-humans-trade/</guid>
      <description>Paper-reading notes: From Tokens To Thoughts: How LLMs And Humans Trade Compression For Meaning</description>
    </item>
    <item>
      <title>Reproducing Robotics Transformer 1</title>
      <link>http://localhost:1313/projects/2026-01-10-reproducing-robotics-transformer-1/</link>
      <pubDate>Sat, 10 Jan 2026 10:14:01 +0000</pubDate>
      <guid>http://localhost:1313/projects/2026-01-10-reproducing-robotics-transformer-1/</guid>
      <description>&lt;p&gt;By the end of the Christmas holidays, I continued my VLA (Vision–Language–Action) learning track. I carefully read two papers: &lt;strong&gt;RT-1: Robotics Transformer for Real-World Control at Scale&lt;/strong&gt; (&lt;a href=&#34;https://arxiv.org/abs/2212.06817&#34;&gt;Brohan et al., 2022&lt;/a&gt;) and &lt;strong&gt;RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control&lt;/strong&gt; (&lt;a href=&#34;https://arxiv.org/abs/2307.15818&#34;&gt;Brohan et al., 2023&lt;/a&gt;) while writing my reading notes here: &lt;a href=&#34;https://mrtanke.github.io/posts/2026-01-09-rt-series/&#34;&gt;https://mrtanke.github.io/posts/2026-01-09-rt-series/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After finishing the notes, I decided to reproduce &lt;strong&gt;Robotics Transformer 1 (RT-1)&lt;/strong&gt; in PyTorch, not to build a production system, but to truly understand the design decisions and implement the core ideas from the paper end-to-end. The goal is a learning-oriented, minimal implementation that stays close to the RT-1 architecture, while keeping the codebase clean and readable. Since training RT-1 at scale requires a heavy TFDS/RLDS pipeline and large real-robot datasets, I intentionally kept the data side minimal: I use a synthetic dataset that mirrors RT-1’s input and output shapes to validate the model forward pass, action tokenization, and the behavioral cloning training loop.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RT Series</title>
      <link>http://localhost:1313/posts/2026-01-09-rt-series/</link>
      <pubDate>Fri, 09 Jan 2026 09:23:14 +0000</pubDate>
      <guid>http://localhost:1313/posts/2026-01-09-rt-series/</guid>
      <description>Paper-reading notes: RT-1 and RT-2</description>
    </item>
    <item>
      <title>Reproducing Diffusion Policy</title>
      <link>http://localhost:1313/projects/2026-01-02-reproducing-diffusion-policy/</link>
      <pubDate>Fri, 02 Jan 2026 19:01:12 +0000</pubDate>
      <guid>http://localhost:1313/projects/2026-01-02-reproducing-diffusion-policy/</guid>
      <description>&lt;p&gt;At the end of 2025, I spent a few days reproducing Diffusion Policy from &lt;a href=&#34;https://arxiv.org/abs/2303.04137&#34;&gt;Diffusion Policy: Visuomotor Policy Learning via Action Diffusion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I first spent about one day to go through the paper. If you are interested, feel free to check &lt;a href=&#34;https://mrtanke.github.io/posts/2025-12-28-diffusion-policy-visuomotor-policy-learning-via-action-diffusion/&#34;&gt;paper reading note&lt;/a&gt;. The work is impressive, so I decided to reproduce it over the Christmas break. This is the repo address &lt;a href=&#34;https://github.com/mrtanke/diffusion-policy&#34;&gt;https://github.com/mrtanke/diffusion-policy&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;repo-skeleton&#34;&gt;Repo skeleton&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;diffusion-policy/&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;diffusion_policy/&lt;/span&gt;                 &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Library&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;code&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(importable&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;package)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;__init__.py&lt;/span&gt;                   &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Package&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;marker&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;checkpoint.py&lt;/span&gt;                 &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Save/load&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;checkpoints&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;normalizer.py&lt;/span&gt;                 &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Min-max&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;normalization&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;to/from&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;-1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;data/&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;pusht_zarr_dataset.py&lt;/span&gt;     &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Load&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;PushT&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;replay&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;training&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;samples:&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;observation&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;history&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;future&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;action&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;trajectory&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;└──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;sequence_utils.py&lt;/span&gt;         &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Builds&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;start/end&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;indices&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;each&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;fixed-length&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;training&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;sample/window&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;within&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;episode&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;   &lt;span class=&#34;err&#34;&gt;└──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;models/&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;       &lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;diffusion.py&lt;/span&gt;              &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;DiffusionPolicy&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;training&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;sampling&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;wrapper&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;       &lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;denoisers.py&lt;/span&gt;              &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Temporal&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;UNet&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;denoiser&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;noise&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;predictor&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;│&lt;/span&gt;       &lt;span class=&#34;err&#34;&gt;└──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;encoders.py&lt;/span&gt;               &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Observation&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;encoder&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;train.py&lt;/span&gt;                          &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Main&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;training&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;entrypoint&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;├──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;eval_pusht.py&lt;/span&gt;                     &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Eval&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;script&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;PushT&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;└──&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;data/pusht/&lt;/span&gt;                       &lt;span class=&#34;err&#34;&gt;#&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;Local&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;dataset&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;folder&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;(pusht_cchi_v&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;_replay.zarr/)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;core-algorithm&#34;&gt;Core algorithm&lt;/h1&gt;
&lt;p&gt;We want to generate an expert action trajectory by &lt;strong&gt;denoising&lt;/strong&gt; a noise action trajectory, just like what Image diffusion do. To do this, we train a model to &lt;strong&gt;predicted the noise&lt;/strong&gt; contained in each action from a noise action tractory. Then we use the predicted noise to gradually denoise the noise action trajectory.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Diffusion Policy: Visuomotor Policy Learning via Action Diffusion</title>
      <link>http://localhost:1313/posts/2025-12-28-diffusion-policy-visuomotor-policy-learning-via-action-diffusion/</link>
      <pubDate>Sun, 28 Dec 2025 15:32:18 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-28-diffusion-policy-visuomotor-policy-learning-via-action-diffusion/</guid>
      <description>Paper-reading notes: Diffusion Policy</description>
    </item>
    <item>
      <title>Synthesizer: Rethinking Self-Attention for Transformer Models</title>
      <link>http://localhost:1313/posts/2025-12-16-synthesizer-rethinking-self-attention-for-transformer-models/</link>
      <pubDate>Tue, 16 Dec 2025 08:40:53 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-16-synthesizer-rethinking-self-attention-for-transformer-models/</guid>
      <description>Paper-reading notes: Synthesizer</description>
    </item>
    <item>
      <title>Learning Transformer Programs</title>
      <link>http://localhost:1313/posts/2025-12-15-learning-transformer-programs/</link>
      <pubDate>Mon, 15 Dec 2025 08:38:28 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-15-learning-transformer-programs/</guid>
      <description>Paper-reading notes: Learning Transformer Programs</description>
    </item>
    <item>
      <title>Reformer: The Efficient Transformer</title>
      <link>http://localhost:1313/posts/2025-12-14-reformer-the-efficient-transformer/</link>
      <pubDate>Sun, 14 Dec 2025 08:39:11 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-14-reformer-the-efficient-transformer/</guid>
      <description>Paper-reading notes: Reformer</description>
    </item>
    <item>
      <title>OpenVLA: An Open-Source Vision-Language-Action Model</title>
      <link>http://localhost:1313/posts/2025-12-12-openvla-an-open-source-vision-language-action-model/</link>
      <pubDate>Fri, 12 Dec 2025 08:37:15 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-12-openvla-an-open-source-vision-language-action-model/</guid>
      <description>Paper-reading notes: OpenVLA</description>
    </item>
    <item>
      <title>Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning</title>
      <link>http://localhost:1313/posts/2025-12-10-bayesian-optimization-is-superior-to-random-search-for-machine-learning-hyperparameter-tuning/</link>
      <pubDate>Wed, 10 Dec 2025 08:36:10 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-10-bayesian-optimization-is-superior-to-random-search-for-machine-learning-hyperparameter-tuning/</guid>
      <description>Paper-reading notes: Bayesian Optimization</description>
    </item>
    <item>
      <title>Random Search for Hyper-Parameter Optimization</title>
      <link>http://localhost:1313/posts/2025-12-10-random-search-for-hyper-parameter-optimization/</link>
      <pubDate>Wed, 10 Dec 2025 08:35:15 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-10-random-search-for-hyper-parameter-optimization/</guid>
      <description>Paper-reading notes: Random Search for Hyper-Parameter Optimization</description>
    </item>
    <item>
      <title>ALTA: Compiler-Based Analysis of Transformers</title>
      <link>http://localhost:1313/posts/2025-12-09-alta-compiler-based-analysis-of-transformers/</link>
      <pubDate>Tue, 09 Dec 2025 08:34:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-09-alta-compiler-based-analysis-of-transformers/</guid>
      <description>Paper-reading notes: ALTA</description>
    </item>
    <item>
      <title>Tracr: Compiled Transformers as a Laboratory for Interpretability</title>
      <link>http://localhost:1313/posts/2025-12-08-tracr-compiled-transformers-as-a-laboratory-for-interpretability/</link>
      <pubDate>Mon, 08 Dec 2025 08:32:26 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-08-tracr-compiled-transformers-as-a-laboratory-for-interpretability/</guid>
      <description>Paper-reading notes: Tracr</description>
    </item>
    <item>
      <title>Thinking Like Transformers</title>
      <link>http://localhost:1313/posts/2025-12-07-thinking-like-transformers/</link>
      <pubDate>Sun, 07 Dec 2025 15:14:48 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-07-thinking-like-transformers/</guid>
      <description>Paper-reading notes: RASP</description>
    </item>
    <item>
      <title>It’s All Connected: A Journey Through Test-Time Memorization, Attentional Bias, Retention, and Online Optimization</title>
      <link>http://localhost:1313/posts/2025-12-06-its-all-connected-a-journey-through-test-time-memorization-attentional-bias-retention-and-online-optimization/</link>
      <pubDate>Sat, 06 Dec 2025 15:13:02 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-06-its-all-connected-a-journey-through-test-time-memorization-attentional-bias-retention-and-online-optimization/</guid>
      <description>Paper-reading notes: MIRAS</description>
    </item>
    <item>
      <title>FNet: Mixing Tokens with Fourier Transforms</title>
      <link>http://localhost:1313/posts/2025-12-05-fnet-mixing-tokens-with-fourier-transforms/</link>
      <pubDate>Fri, 05 Dec 2025 15:11:32 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-05-fnet-mixing-tokens-with-fourier-transforms/</guid>
      <description>Paper-reading notes: FNet</description>
    </item>
    <item>
      <title>Linformer: Self-Attention with Linear Complexity</title>
      <link>http://localhost:1313/posts/2025-12-04-linformer-self-attention-with-linear-complexity/</link>
      <pubDate>Thu, 04 Dec 2025 15:10:45 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-04-linformer-self-attention-with-linear-complexity/</guid>
      <description>Paper-reading notes: Linformer</description>
    </item>
    <item>
      <title>Rethinking Attention with Performers</title>
      <link>http://localhost:1313/posts/2025-12-03-rethinking-attention-with-performers/</link>
      <pubDate>Wed, 03 Dec 2025 15:09:23 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-03-rethinking-attention-with-performers/</guid>
      <description>Paper-reading notes: Performers</description>
    </item>
    <item>
      <title>On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning</title>
      <link>http://localhost:1313/posts/2025-12-01-on-the-representational-capacity-of-neural-language-models-with-chain-of-thought-reasoning/</link>
      <pubDate>Mon, 01 Dec 2025 08:49:03 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-12-01-on-the-representational-capacity-of-neural-language-models-with-chain-of-thought-reasoning/</guid>
      <description>Paper-reading notes: On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning</description>
    </item>
    <item>
      <title>What Formal Languages Can Transformers Express? A Survey</title>
      <link>http://localhost:1313/posts/2025-11-30-what-formal-languages-can-transformers-express-a-survey/</link>
      <pubDate>Sun, 30 Nov 2025 08:47:55 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-30-what-formal-languages-can-transformers-express-a-survey/</guid>
      <description>Paper-reading notes: What Formal Languages Can Transformers Express? A Survey</description>
    </item>
    <item>
      <title>ATLAS: Learning to Optimally Memorize the Context at Test Time</title>
      <link>http://localhost:1313/posts/2025-11-29-atlas-learning-to-optimally-memorize-the-context-at-test-time/</link>
      <pubDate>Sat, 29 Nov 2025 08:46:44 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-29-atlas-learning-to-optimally-memorize-the-context-at-test-time/</guid>
      <description>Paper-reading notes: ATLAS</description>
    </item>
    <item>
      <title>Solving olympiad geometry without human demonstrations</title>
      <link>http://localhost:1313/posts/2025-11-28-solving-olympiad-geometry-without-human-demonstrations/</link>
      <pubDate>Fri, 28 Nov 2025 08:42:56 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-28-solving-olympiad-geometry-without-human-demonstrations/</guid>
      <description>Paper-reading notes: AlphaGeometry</description>
    </item>
    <item>
      <title>Formal Mathematical Reasoning A New Frontier in AI</title>
      <link>http://localhost:1313/posts/2025-11-27-formal-mathematical-reasoning-a-new-frontier-in-ai/</link>
      <pubDate>Thu, 27 Nov 2025 08:42:29 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-27-formal-mathematical-reasoning-a-new-frontier-in-ai/</guid>
      <description>Paper-reading notes: Formal Mathematical Reasoning A New Frontier in AI</description>
    </item>
    <item>
      <title>Titans: Learning to Memorize at Test Time</title>
      <link>http://localhost:1313/posts/2025-11-26-titans-learning-to-memorize-at-test-time/</link>
      <pubDate>Wed, 26 Nov 2025 08:42:17 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-26-titans-learning-to-memorize-at-test-time/</guid>
      <description>Paper-reading notes: Titans</description>
    </item>
    <item>
      <title>Roformer: Enhanced Transformer With Rotary Position Embedding</title>
      <link>http://localhost:1313/posts/2025-11-25-roformer-enhanced-transformer-with-rotary-position-embedding/</link>
      <pubDate>Tue, 25 Nov 2025 08:40:15 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-25-roformer-enhanced-transformer-with-rotary-position-embedding/</guid>
      <description>Paper-reading notes: Roformer</description>
    </item>
    <item>
      <title>Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</title>
      <link>http://localhost:1313/posts/2025-11-24-mastering-chess-and-shogi-by-self-play-with-a-general-reinforcement-learning-algorithm/</link>
      <pubDate>Mon, 24 Nov 2025 08:39:45 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-24-mastering-chess-and-shogi-by-self-play-with-a-general-reinforcement-learning-algorithm/</guid>
      <description>Paper-reading notes: AlphaZero</description>
    </item>
    <item>
      <title>Mastering the game of Go without human knowledge</title>
      <link>http://localhost:1313/posts/2025-11-24-mastering-the-game-of-go-without-human-knowledge/</link>
      <pubDate>Mon, 24 Nov 2025 08:38:30 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-24-mastering-the-game-of-go-without-human-knowledge/</guid>
      <description>Paper-reading notes: AlphaGo Zero</description>
    </item>
    <item>
      <title>Disentangling Light Fields for Super-Resolution and Disparity Estimation</title>
      <link>http://localhost:1313/posts/2025-11-19-disentangling-light-fields-for-super-resolution-and-disparity-estimation/</link>
      <pubDate>Wed, 19 Nov 2025 07:42:14 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-19-disentangling-light-fields-for-super-resolution-and-disparity-estimation/</guid>
      <description>Paper-reading notes: Distangling mechanism, DistgSSR, DistgASR, DistgDisp</description>
    </item>
    <item>
      <title>Hyena Hierarchy: Towards Larger Convolutional Language Models</title>
      <link>http://localhost:1313/posts/2025-11-18-hyena-hierarchy-towards-larger-convolutional-language-models/</link>
      <pubDate>Tue, 18 Nov 2025 07:39:29 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-18-hyena-hierarchy-towards-larger-convolutional-language-models/</guid>
      <description>Paper-reading notes: Hyena Hierarchy</description>
    </item>
    <item>
      <title>Mamba: Linear-Time Sequence Modeling with Selective State Spaces</title>
      <link>http://localhost:1313/posts/2025-11-17-mamba-linear-time-sequence-modeling-with-selective-state-spaces/</link>
      <pubDate>Mon, 17 Nov 2025 07:38:28 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-17-mamba-linear-time-sequence-modeling-with-selective-state-spaces/</guid>
      <description>Paper-reading notes: Mamba</description>
    </item>
    <item>
      <title>A survey for light field super-resolution</title>
      <link>http://localhost:1313/posts/2025-11-14-a-survey-for-light-field-super-resolution/</link>
      <pubDate>Fri, 14 Nov 2025 07:41:11 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-14-a-survey-for-light-field-super-resolution/</guid>
      <description>Paper-reading notes: A survey for light field super-resolution</description>
    </item>
    <item>
      <title>Efficiently Modeling Long Sequences with Structured State Spaces</title>
      <link>http://localhost:1313/posts/2025-11-11-efficiently-modeling-long-sequences-with-structured-state-spaces/</link>
      <pubDate>Tue, 11 Nov 2025 13:19:33 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-11-efficiently-modeling-long-sequences-with-structured-state-spaces/</guid>
      <description>Paper-reading notes: S4</description>
    </item>
    <item>
      <title>Retentive Network: A Successor to Transformer for Large Language Models</title>
      <link>http://localhost:1313/posts/2025-11-11-retentive-network-a-successor-to-transformer-for-large-language-models/</link>
      <pubDate>Tue, 11 Nov 2025 10:20:33 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-11-retentive-network-a-successor-to-transformer-for-large-language-models/</guid>
      <description>Paper-reading notes: RetNet</description>
    </item>
    <item>
      <title>Exploiting Spatial and Angular Correlations With Deep Efficient Transformers for Light Field Image Super-Resolution</title>
      <link>http://localhost:1313/posts/2025-11-10-exploiting-spatial-and-angular-correlations-with-deep-efficient-transformers-for-light-field-image-super-resolution/</link>
      <pubDate>Mon, 10 Nov 2025 13:22:13 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-10-exploiting-spatial-and-angular-correlations-with-deep-efficient-transformers-for-light-field-image-super-resolution/</guid>
      <description>Paper-reading notes: LF-DET</description>
    </item>
    <item>
      <title>Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation</title>
      <link>http://localhost:1313/posts/2025-11-09-mixture-of-recursions-learning-dynamic-recursive-depths-for-adaptive-token-level-computation/</link>
      <pubDate>Sun, 09 Nov 2025 15:01:10 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-09-mixture-of-recursions-learning-dynamic-recursive-depths-for-adaptive-token-level-computation/</guid>
      <description>Paper-reading notes: Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation</description>
    </item>
    <item>
      <title>Reference-Based Face Super-Resolution Using the Spatial Transformer</title>
      <link>http://localhost:1313/posts/2025-11-07-reference-based-face-super-resolution-using-the-spatial-transformer/</link>
      <pubDate>Fri, 07 Nov 2025 09:32:10 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-07-reference-based-face-super-resolution-using-the-spatial-transformer/</guid>
      <description>Paper-reading notes: Reference-Based Face Super-Resolution Using the Spatial Transformer</description>
    </item>
    <item>
      <title>LMR: A Large-Scale Multi-Reference Dataset for Reference-based Super-Resolution</title>
      <link>http://localhost:1313/posts/2025-11-07-lmr-a-large-scale-multi-reference-dataset-for-reference-based-super-resolution/</link>
      <pubDate>Fri, 07 Nov 2025 08:38:54 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-07-lmr-a-large-scale-multi-reference-dataset-for-reference-based-super-resolution/</guid>
      <description>Paper-reading notes: LMR - A Large-Scale Multi-Reference Dataset for Reference-based Super-Resolution</description>
    </item>
    <item>
      <title>Latent Diffusion Models</title>
      <link>http://localhost:1313/posts/2025-11-06-latent-diffusion-models/</link>
      <pubDate>Thu, 06 Nov 2025 21:19:54 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-06-latent-diffusion-models/</guid>
      <description>Paper-reading notes: High-Resolution Image Synthesis with Latent Diffusion Models</description>
    </item>
    <item>
      <title>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</title>
      <link>http://localhost:1313/posts/2025-11-04-deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/</link>
      <pubDate>Tue, 04 Nov 2025 12:06:46 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-04-deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning/</guid>
      <description>Paper-reading notes: DeepSeek-R1 - Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</description>
    </item>
    <item>
      <title>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
      <link>http://localhost:1313/posts/2025-11-03-an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/</link>
      <pubDate>Mon, 03 Nov 2025 12:36:53 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-03-an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale/</guid>
      <description>Paper-reading notes: ViT</description>
    </item>
    <item>
      <title>A Tutorial on Bayesian Optimization</title>
      <link>http://localhost:1313/posts/2025-11-01-a-tutorial-on-bayesian-optimization/</link>
      <pubDate>Sat, 01 Nov 2025 23:05:46 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-11-01-a-tutorial-on-bayesian-optimization/</guid>
      <description>Paper-reading notes: A Tutorial on Bayesian Optimization</description>
    </item>
    <item>
      <title>CrossNet&#43;&#43;: Cross-Scale Large-Parallax Warping for Reference-Based Super-Resolution</title>
      <link>http://localhost:1313/posts/2025-10-29-crossnet-cross-scale-large-parallax-warping-for-reference-based-super-resolution/</link>
      <pubDate>Wed, 29 Oct 2025 08:23:31 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-29-crossnet-cross-scale-large-parallax-warping-for-reference-based-super-resolution/</guid>
      <description>Paper-reading notes: CrossNet&#43;&#43;: Cross-Scale Large-Parallax Warping for Reference-Based Super-Resolution</description>
    </item>
    <item>
      <title>xLSTM: Extended Long Short-Term Memory</title>
      <link>http://localhost:1313/posts/2025-10-28-xlstm-extended-long-short-term-memory/</link>
      <pubDate>Tue, 28 Oct 2025 13:18:30 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-28-xlstm-extended-long-short-term-memory/</guid>
      <description>Paper-reading notes: xLSTM Extended Long Short-Term Memory</description>
    </item>
    <item>
      <title>RWKV: Reinventing RNNs for the Transformer Era</title>
      <link>http://localhost:1313/posts/2025-10-27-rwkv-reinventing-rnns-for-the-transformer-era/</link>
      <pubDate>Mon, 27 Oct 2025 22:50:43 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-27-rwkv-reinventing-rnns-for-the-transformer-era/</guid>
      <description>Paper-reading notes: RWKV: Reinventing RNNs for the Transformer Era</description>
    </item>
    <item>
      <title>Mastering the game of Go with MCTS and Deep Neural Networks</title>
      <link>http://localhost:1313/posts/2025-10-24-mastering-the-game-of-go-with-mcts-and-deep-neural-networks/</link>
      <pubDate>Fri, 24 Oct 2025 10:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-24-mastering-the-game-of-go-with-mcts-and-deep-neural-networks/</guid>
      <description>Paper-reading notes: Mastering the game of Go with MCTS and Deep Neural Networks</description>
    </item>
    <item>
      <title>CrossNet: An End-to-end Reference-based Super Resolution Network using Cross-scale Warping</title>
      <link>http://localhost:1313/posts/2025-10-21-crossnet-an-end-to-end-reference-based-super-resolution-network-using-cross-scale-warping/</link>
      <pubDate>Tue, 21 Oct 2025 09:40:06 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-21-crossnet-an-end-to-end-reference-based-super-resolution-network-using-cross-scale-warping/</guid>
      <description>Paper-reading notes: CrossNet: An End-to-end Reference-based Super Resolution Network using Cross-scale Warping</description>
    </item>
    <item>
      <title>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</title>
      <link>http://localhost:1313/posts/2025-10-20-chain-of-thought-prompting-elicits-reasoning-in-large-language-models/</link>
      <pubDate>Mon, 20 Oct 2025 13:58:55 +0200</pubDate>
      <guid>http://localhost:1313/posts/2025-10-20-chain-of-thought-prompting-elicits-reasoning-in-large-language-models/</guid>
      <description>Paper-reading notes: Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</description>
    </item>
    <item>
      <title>Learning‑based light field imaging</title>
      <link>http://localhost:1313/posts/2025-10-20-learningbased-light-field-imaging/</link>
      <pubDate>Mon, 20 Oct 2025 09:50:58 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-20-learningbased-light-field-imaging/</guid>
      <description>Paper-reading notes: Learning‑based light field imaging</description>
    </item>
    <item>
      <title>From Local to Global: A GraphRAG Approach to Query-Focused Summarization</title>
      <link>http://localhost:1313/posts/2025-10-16-from-local-to-global-a-graphrag-approach-to-query-focused-summarization/</link>
      <pubDate>Thu, 16 Oct 2025 19:42:01 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-16-from-local-to-global-a-graphrag-approach-to-query-focused-summarization/</guid>
      <description>Paper-reading notes: GraphRAG</description>
    </item>
    <item>
      <title>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</title>
      <link>http://localhost:1313/posts/2025-10-15-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks/</link>
      <pubDate>Wed, 15 Oct 2025 09:43:53 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-15-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks/</guid>
      <description>Paper-reading notes: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</description>
    </item>
    <item>
      <title>A Bridging Model for Parallel Computation</title>
      <link>http://localhost:1313/posts/2025-10-10-a-bridging-model-for-parallel-computation/</link>
      <pubDate>Fri, 10 Oct 2025 12:30:04 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-10-a-bridging-model-for-parallel-computation/</guid>
      <description>Paper-reading notes: A Bridging Model for Parallel Computation</description>
    </item>
    <item>
      <title>Attention is All You Need</title>
      <link>http://localhost:1313/posts/2025-10-01-attention-is-all-you-need/</link>
      <pubDate>Wed, 01 Oct 2025 00:36:58 +0000</pubDate>
      <guid>http://localhost:1313/posts/2025-10-01-attention-is-all-you-need/</guid>
      <description>Paper-reading notes: Attention is All You Need</description>
    </item>
  </channel>
</rss>
